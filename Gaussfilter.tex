\chapter{Gaußfilter für lineare Systeme}
Das allgemeine Bayes Filter lässt sich für allgemeine PDFs nur schwer auswerten. 
Daher werden die PDFs als Normalverteilungen angenommen:
\begin{equation*}
    p(x) = \abs{2 \pi P}^{-\frac{1}{2}} \exp \left(-\frac{1}{2} \T{(x - \bar{x})} P^{-1} (x-\bar{x}) \right)
\end{equation*}
Mit $\bar{x}$: Erwartungswert, $P$: Kovarianzmatrix.

\section{Definitionen}
Ein (lineares) Systemmodell sei gegeben durch:
\begin{equation*}
    x(k+1) = F(k) x(k) + G(k) u(k) + v(k)
\end{equation*}
mit:
\begin{itemize}
    \item $x(k) \in \mathbb{R}^{n \times 1}$: Zustandsvektor
    \item $u(k) \in \mathbb{R}^{j \times 1}$: Steuervektor
    \item $u(k) \in \mathbb{R}^{j \times 1}$: Sequenz von gaußverteiltem, mittelwertfreien weißem Rauschen
    \item $F(k) \in \mathbb{R}^{n \times n}$: Systemmatrix
    \item $G(k) \in \mathbb{R}^{n \times j}$: Steuermatrix
    \item $k \in \mathbb{N}$ Zeitindex der diskreten Zeit
\end{itemize}
Das Modellrauschen hat die Kovarianz:
\begin{equation*}
    Q(k) = \E{v(k)\T{v(k)}}
\end{equation*}

Sowie die Messgleichung:
\begin{equation*}
    z(k) = H(k) x(k) + w(k)
\end{equation*}
mit:
\begin{itemize}
    \item $z(k) \in \mathbb{R}^{m \times 1}$: Messvektor
    \item $H(k) \in \mathbb{R}^{m \times n}$: Messmatrix
    \item $w(k) \in \mathbb{R}^{m \times 1}$: Sequenz von gaußverteiltem, mittelwertfreiem, weißen Rauschen
\end{itemize}
Das Messrauschen hat die Kovarianz:
\begin{equation*}
    R(k) = \E{w(k)\T{w(k)}}
\end{equation*}

Zudem seien die beiden Rauschprozesse (System- und Modellrauschen) statistisch unabhängig, d.h.
die Kreuzkorrelation ergibt sich zu null.

Um abhängigkeiten des Modelrauschens zu modellieren wird das Rauschen z.t. als $\Gamma(k) v(k)$, mit
$\Gamma \in \mathbb{R}^{n \times i}$ gewählt. Die Kovarianz ist dann:
\begin{equation*}
    \E{(\Gamma(k)v(k))\T{(\Gamma(k)v(k))}} = \Gamma(k) Q(k) \T{\Gamma(k)}
\end{equation*}

\section{Kalmanfilter}
\subsection{Prädiktionsschritt}
\begin{itemize}
    \item Zustandsprädiktion:
        \begin{equation*}
            \hat{x}(k+1|k) = F(k) \hat{x}(k|k) + G(k) u(k)
        \end{equation*} 
    \item Kovarianzprädiktion:
        \begin{equation*}
            P(k+1|k) = F(k)P(k|k)\T{F(k)} + Q(k)
        \end{equation*}
    \item Messwertprädiktion:
        \begin{equation*}
            \hat{z}(k+1|k) = H(k+1) \hat{x}(k+1|k)
        \end{equation*}
    \item Kovarianz-Messwertprädiktion:
        \begin{equation*}
            S(k+1) = H(k+1)P(k+1|k)\T{H(k+1)} + R(k+1)
        \end{equation*}
\end{itemize}

\subsection{Innovationsschritt}
\begin{itemize}
    \item Filterverstärkung;
        \begin{equation*}
            K(k+1) = P(k+1|k) \T{H(k+1)} {S(k+1)}^{-1}
        \end{equation*}
    \item Zustandsupdate
        \begin{equation*}
            \hat{x}(k+1|k+1) = \hat{x}(k+1|k) + K(k+1) \gamma(k+1)
        \end{equation*}
        mit dem Messresiduum
        \begin{equation*}
            \gamma(k+1) = z(k+1) - \hat{z}(k+1|k)
        \end{equation*}
    \item Kovarianzupdate
        \begin{equation*}
            P(k+1|k+1) = P(k+1|k) - K(k+1) S(k+1) \T{K(k+1)}
        \end{equation*}
\end{itemize}

\section{Konsistenz von Zustandsschätzern}
Im Gegensatz zur (statischen) Parameterschätzung kann bei der (dynamischen) Zustandsschätzung nicht die Konvergenz gefordert werden, stattdessen soll gelten:
\begin{eqnarray*}
    \E{x(k) - \hat{x}(k|k)} &=& \E{\hat{x}(k|k)} = 0 \\
    \E{\tilde{x}(k|k) \T{\tilde{x}(k|k)}} &=& P(k|k) 
\end{eqnarray*}
D.h. die Schätzung soll Offsetfrei sein und der MSE mit der Varianz übereinstimmen.

Falls die zweite Bedingung zutrifft so trifft auch implizit die erste zu, da sonst das Offset additiv den MSE beeinflussen würde.

\subsection{Normalized Estimation Error Squared (NEES)}
\begin{equation*}
    \varepsilon(k) = \T{\tilde{x}(k|k)} P^{-1}(k|k)\tilde{x}(k|k)
\end{equation*}
Wenn das Filter konsistent ist und es sich um ein lineares System mit normalverteilten Fehler handelt, dann ist die quadratische Form $\chi^2$-verteilt mit $\dim[x]$ Freiheitsgraden, d.h.:
\begin{equation*}
    \E{\varepsilon(k)} = \dim[k]
\end{equation*}

Es muss also untersucht werden ob solche eine $\chi^2$-Verteilung vorliegt.

\subsubsection{Tests, basierend auf Monte-Carlo-Simulationen}
Für den NEES-Wert muss der Zustand $x$ bekannt sein, das heißt der Score kann nur auf Basis von Simulationen berechnet
werden.

Dafür wird über $N$ Simulationsläufe jeweils $\varepsilon$ berechnet. Es muss dann gelten,
dass:
\begin{equation*}
    \sum_{i=1}^N \varepsilon^i(k) \propto \chi^2_{N \dim[x]}
\end{equation*}

Das kann mit einem $\chi^2$ Test überprüft werden:
Es wird ein Interval $[r_1, r_2]$ gewählt, mit ($x$ folgt der $\chi^2$-Verteilung):
\begin{equation*}
    P(x \in [r_1, r_2]) = 1 - \alpha
\end{equation*}
Wobei $\alpha$ das Signifikanzniveau ist, das heißt, die Wahrscheinlichkeit, dass nicht in diesem Interval ist, obwohl $x$ einer $\chi^2$-Verteilung folgt ist $\alpha$.

\subsection{Normalized innovation squared (NIS)}
Da der NEES-Wert den echten Zustand $x$ nutzt, ist es nicht möglich die Konsistenz des Filters online zu bestimmen. Das ist mit dem NIS Wert möglich:
\begin{equation*}
    \bar{\varepsilon}_\gamma = \frac{1}{k} \sum_{i=1}^k \T{\gamma(i)} {S(i)}^{-1} \gamma(i)
\end{equation*}
Auch diese muss einer $\chi^2$-Verteilung folgen, siehe NEES.

\section{Filterinitialisierung}
Für einen kurzen Einschwingvorgang des Filters sollte die initialie Zustands- und Kovarianzschätzung passend gewählt werden. Das heißt das Filter sollte Konsistent sein:
\begin{equation*}
    \T{\tilde{x}(0|0)} {P(0|0)^{-1}} \tilde{x}(0|0) \leq c_1
\end{equation*}
wobei $c_1$ die obere Grenze des 95\% Vertrauensbereichs der $\chi^2$-Verteilung 
mit der entsprechenden Anzahl an Freiheitsgraden darstellt.

\section{Lineare Modelle}
\subsection{Konstante Position}
\begin{eqnarray*}
    x &=& \begin{pmatrix} x\end{pmatrix} \\
    F &=& \begin{pmatrix} 1\end{pmatrix} \\
    \Gamma &=& \begin{pmatrix} T \end{pmatrix} \\
    \text{bzw. } Q &=& 
        \begin{pmatrix} 
            T^2 
        \end{pmatrix}
        \sigma^2_v \\
\end{eqnarray*}

\subsection{Konstante Geschwindigkeit (DWNA/CV)}
\begin{eqnarray*}
    x &=& \begin{pmatrix} x \\ \dot{x} \end{pmatrix} \\
    F &=& \begin{pmatrix} 1 & T \\ 0 & 1 \end{pmatrix} \\
    \Gamma &=& \begin{pmatrix} \frac{1}{2} T^2 \\ T \end{pmatrix} \\
    \text{bzw. } Q &=& 
        \begin{pmatrix} 
            \frac{1}{4} T^4 & \frac{1}{2} T^3 \\ 
            \frac{1}{2} T^3 & T^2 
        \end{pmatrix}
        \sigma^2_v \\
\end{eqnarray*}

\subsection{Konstante Beschleunigung}
\begin{eqnarray*}
    x &=& \begin{pmatrix} x \\ \dot{x} \\ \ddot{x} \end{pmatrix} \\
    F &=& \begin{pmatrix} 1 & T & \frac{1}{2} T^2 \\ 0 & 1 & T \\ 0 & 0 & 1 \end{pmatrix} \\
    \Gamma &=& \begin{pmatrix} \frac{1}{2} T^2 \\ T \\ 1 \end{pmatrix} \\
    \text{bzw. } Q &=& 
        \begin{pmatrix} 
            \frac{1}{4} T^4 & \frac{1}{2} T^3 & \frac{1}{2} T^2 \\ 
            \frac{1}{2} T^3 & T^2 & T \\
            \frac{1}{2} T^2 & T & 1 
        \end{pmatrix}
        \sigma^2_v \\
\end{eqnarray*}

\section{Stationäres Kalmanfilter}
\subsection{$\alpha$-$\beta$-Tracker}
Für ein CV-Modell mit konstanten Parametern konvergieren die Parameter des Kalmanfilters 
(Filterverstärkung, Kovarianzen) gegen feste Parameter, diese können auch Offline berechnet werden.

Es wird ein CV-Modell mit $H = \begin{pmatrix} 1 & 0 \end{pmatrix}$ angenommen.

Für die Grenzwerte der Matrizen gilt:
\begin{eqnarray*}
    \lim_{k \to \infty} P(k|k) &=& \begin{pmatrix} p_{ij} \end{pmatrix} \\
    \lim_{k \to \infty} P(k+1|k) &=& \begin{pmatrix} m_{ij} \end{pmatrix} \\
    \lim_{k \to \infty} K(k) &=& \begin{pmatrix} g_1 \\ g_2  \end{pmatrix} \\
        &=& \begin{pmatrix} \alpha \\ \frac{\beta}{T} \end{pmatrix}
\end{eqnarray*}
Daraus folgt:
\begin{eqnarray*}
    S &=& H
        \begin{pmatrix}
            m_{11} & m_{12} \\
            m_{12} & m_{22} 
        \end{pmatrix}
        \T{H} + R = m_{11} + \sigma_w^2 \\
    K &=&
        \begin{pmatrix}
            m_{11} & m_{12} \\
            m_{12} & m_{22}
        \end{pmatrix} \T{H} S^{-1} = 
        \begin{pmatrix}
            \frac{m_{11}}{m_{11} + \sigma_w^2} \\
            \frac{m_{12}}{m_{11} + \sigma_w^2}
        \end{pmatrix} \\
    \Rightarrow && \\
    g_1 &=& \alpha = \frac{m_{11}}{m_{11} + \sigma_w^2} \\
    g_2 &=& \frac{\beta}{T} = g_1 \frac{m_{12}}{m_{11}} \\
    P(k|k) &=& P(k+1|k) \T{H} S^{-1} = 
        \begin{pmatrix}
            (1-g_1) m_{11} & (1-g_1) m_{12} \\
            (1-g_1) m_{12} & m_{22} - g_2 m_{12}
        \end{pmatrix}
\end{eqnarray*}
Mit den bekannten System- und Kalmangleichungen gilt (zeitinvarianz vorausgesetzt):
\begin{eqnarray*}
    P(k+1|k) &=& F P(k|k) \T{F} + Q \\
    \Leftrightarrow P(k|k) &=& F^{-1} (P(k+1|k) - Q) \T{\left(F^{-1}\right)} \\
    P(k|k) &=&
        \begin{pmatrix}
            m_{11} - 2 T m_{12} + T^2 m_{22} - \frac{1}{4} T^4 \sigma_v^2 & m_{12} - T m_{22} + \frac{1}{2} T^3 \sigma_v^2 \\
            m_{12} - T m_{22} + \frac{1}{2} T^3 \sigma_v^2 & m_{22} - T^2 \sigma_v^2
        \end{pmatrix}
\end{eqnarray*}
Durch Gleichsetzen erhält man:
\begin{eqnarray*}
    g_1 m_{11} &=& 2 T m_{12} - T^2 m_{22} + \frac{T^4}{4} \sigma_v^2 \\
    g_1 m_{12} &=& T m_{22} - \frac{T^3}{2} \sigma_v^2 \\
    g_2 m_{12} &=& T^2 \sigma_v^2
\end{eqnarray*} 

Durch Kombination erhält man:
\begin{eqnarray*}
    \alpha &=& - \frac{1}{8} \left( \lambda^2 + 8 \lambda - (\lambda + 4) \sqrt{\lambda^2 + 8 \lambda} \right) \\
    \beta &=& \frac{1}{4} \left( \lambda^2 + 4\lambda - \lambda \sqrt{\lambda^2 + 8 \lambda} \right) \\
    \text{mit } \lambda &=& \frac{\sigma_v T^2}{\sigma_w} 
\end{eqnarray*}

für die Kovarianzmatrix gilt:
\begin{eqnarray*}
    p_{11} &=& \alpha \sigma_w^2 \\
    p_{12} &=& \frac{\beta}{T} \sigma_w^2 \\
    p_{22} &=& \frac{\beta}{T^2} \frac{\alpha-\frac{\beta}{2}}{1-\alpha} \sigma_w^2
\end{eqnarray*}

\subsection{$\alpha$-$\beta$-$\gamma$-Tracker}
Eine ähnliche Rechung lässt sich auch für ein Modell 3. Ordnung anstellen, es resultiert (bei gleichem $\lambda$):
\begin{equation*}
    \lim_{k \to \infty} =
        \begin{pmatrix}
            g_1 \\ g_2 \\ g_3
        \end{pmatrix} =
        \begin{pmatrix}
            \alpha \\ \frac{\beta}{T} \\ \frac{\gamma}{2 T^2}
        \end{pmatrix}
\end{equation*}
die Beziehung zwischen den Parametern lautet:
\begin{eqnarray*}
    \lambda^2 &=& \frac{\gamma^2}{4 (1-\alpha)} \\
    \alpha &=& \sqrt{2 \beta} - \frac{\beta}{2} \\
    \beta &=& 2(2-\alpha) - 4 \sqrt{1-\alpha} \\
    \gamma &=& \frac{\beta^2}{\alpha}
\end{eqnarray*}

für die Kovarianzmatrix gilt:
\begin{eqnarray*}
    p_{11} &=& \alpha \sigma_w^2 \\
    p_{12} &=& \frac{\beta}{T} \sigma_w^2 \\
    p_{13} &=& \frac{\gamma}{2T^2} \sigma_w^2 \\
    p_{22} &=& \frac{8 \alpha \beta + \gamma (\beta - 2 \alpha -4)}{8 T^2 (1-\alpha)} \sigma_w^2 \\
    p_{23} &=& \frac{\beta (2\beta - \gamma)}{4 T^2 (1- \alpha)} \sigma_w^2 \\
    p_{33} &=& \frac{\gamma (2 \beta - \gamma)}{4 T^4 (1-\alpha)} \sigma_w^2
\end{eqnarray*}
